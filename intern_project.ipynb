{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "291aff2e-7ac3-4a36-bcc3-31a3faa4f28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Japanese Dataset:\n",
      "           ID  CURR_AGE GENDER  ANN_INCOME  AGE_CAR  PURCHASE\n",
      "0  00001Q15YJ        50      M      445344      439         0\n",
      "1  00003I71CQ        35      M      107634      283         0\n",
      "2  00003N47FS        59      F      502787      390         1\n",
      "3  00005H41DE        43      M      585664      475         0\n",
      "4  00007E17UM        39      F      705723      497         1\n",
      "\n",
      "Indian Dataset:\n",
      "           ID  CURR_AGE GENDER  ANN_INCOME             DT_MAINT\n",
      "0  20710B05XL        54      M     1425390            4/20/2018\n",
      "1  89602T51HX        47      M     1678954  2018-08-06 00:00:00\n",
      "2  70190Z52IP        60      M      931624            7/31/2017\n",
      "3  25623V15MU        55      F     1106320            7/31/2017\n",
      "4  36230I68CE        32      F      748465            1/27/2019\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "japanese_data = pd.read_excel('C:/Users/DELL/Documents/AI/excel file/project1.xlsx')\n",
    "indian_data = pd.read_excel('C:/Users/DELL/Documents/AI/excel file/prjdataset1.xlsx')\n",
    "\n",
    "# Display the first few rows of each dataset\n",
    "print(\"Japanese Dataset:\")\n",
    "print(japanese_data.head())\n",
    "print(\"\\nIndian Dataset:\")\n",
    "print(indian_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1af2347-82b2-429f-aed2-a8c42c984114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns in Indian dataset: Index(['CURR_AGE', 'ANN_INCOME'], dtype='object')\n",
      "Categorical columns in Indian dataset: Index(['ID', 'GENDER', 'DT_MAINT'], dtype='object')\n",
      "Numeric columns in Japanese dataset: Index(['CURR_AGE', 'ANN_INCOME', 'AGE_CAR', 'PURCHASE'], dtype='object')\n",
      "Categorical columns in Japanese dataset: Index(['ID', 'GENDER'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Identify numeric and categorical columns\n",
    "numeric_cols_indian = indian_data.select_dtypes(include=['number']).columns\n",
    "categorical_cols_indian = indian_data.select_dtypes(include=['object']).columns\n",
    "\n",
    "numeric_cols_japanese = japanese_data.select_dtypes(include=['number']).columns\n",
    "categorical_cols_japanese = japanese_data.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(\"Numeric columns in Indian dataset:\", numeric_cols_indian)\n",
    "print(\"Categorical columns in Indian dataset:\", categorical_cols_indian)\n",
    "print(\"Numeric columns in Japanese dataset:\", numeric_cols_japanese)\n",
    "print(\"Categorical columns in Japanese dataset:\", categorical_cols_japanese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad18828a-3589-452a-bcc0-041ba3fc977c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'CURR_AGE', 'GENDER', 'ANN_INCOME', 'AGE_CAR', 'PURCHASE'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(japanese_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf6676d3-4e5e-4d96-a35f-ae18c9f42cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the DataFrame: Index(['ID', 'CURR_AGE', 'GENDER', 'ANN_INCOME', 'AGE_CAR', 'PURCHASE'], dtype='object')\n",
      "Preprocessing completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Sample data\n",
    "data = pd.read_excel('C:/Users/DELL/Documents/AI/excel file/project1.xlsx')\n",
    "japanese_data = pd.DataFrame(data)\n",
    "\n",
    "# Check the columns in the DataFrame\n",
    "print(\"Columns in the DataFrame:\", japanese_data.columns)\n",
    "\n",
    "# Ensure 'PURCHASE' column exists\n",
    "if 'PURCHASE' not in japanese_data.columns:\n",
    "    raise ValueError(\"The column 'PURCHASE' is not found in the DataFrame\")\n",
    "\n",
    "# Define feature and target variables\n",
    "X = japanese_data[['CURR_AGE', 'ANN_INCOME', 'AGE_CAR', 'GENDER']]\n",
    "y = japanese_data['PURCHASE']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the preprocessing pipeline\n",
    "numeric_features = ['CURR_AGE', 'ANN_INCOME', 'AGE_CAR']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_features = ['GENDER']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Apply the preprocessing pipeline\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "print(\"Preprocessing completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6048483e-55ec-46a0-9c47-93de1a559a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.61      0.62      2964\n",
      "           1       0.71      0.73      0.72      3856\n",
      "\n",
      "    accuracy                           0.68      6820\n",
      "   macro avg       0.67      0.67      0.67      6820\n",
      "weighted avg       0.68      0.68      0.68      6820\n",
      "\n",
      "[[1804 1160]\n",
      " [1031 2825]]\n",
      "ROC-AUC Score: 0.7470056042496123\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5eb71958-a311-4744-a275-878e5dd2889b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimated number of potential customers in the Indian market: 65855\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Sample data (to be replaced with your actual Indian dataset)\n",
    "indian_data =  pd.read_excel('C:/Users/DELL/Documents/AI/excel file/INDIAN.xlsx')\n",
    "\n",
    "# Drop the target column from the Indian dataset to get feature columns\n",
    "indian_X = indian_data[['CURR_AGE', 'ANN_INCOME','DT_MAINT','GENDER','AGE_CAR']]\n",
    "\n",
    "# Apply the preprocessing pipeline to the Indian dataset\n",
    "indian_X_transformed = preprocessor.transform(indian_X)\n",
    "\n",
    "# Assuming 'model' is already trained\n",
    "indian_y_pred = model.predict(indian_X_transformed)\n",
    "\n",
    "# Estimate the number of potential customers in the Indian market\n",
    "potential_customers = sum(indian_y_pred)\n",
    "\n",
    "print(\"\\nEstimated number of potential customers in the Indian market:\", potential_customers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c52e287-a274-4322-9859-f24b5b89ad0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to Excel files successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "indian_data_processed = pd.DataFrame(indian_X_transformed, columns=preprocessor.get_feature_names_out())\n",
    "japanese_data_processed = pd.DataFrame(X_test, columns=preprocessor.get_feature_names_out())\n",
    "\n",
    "# Add the PURCHASE column\n",
    "indian_data_processed['PURCHASE'] = indian_y_pred\n",
    "japanese_data_processed['PURCHASE'] = y_test.values  # Ensure PURCHASE is aligned with the test set\n",
    "\n",
    "# Save to Excel files\n",
    "indian_data_processed.to_excel('indian_data_processed.xlsx', index=False)\n",
    "japanese_data_processed.to_excel('japanese_data_processed.xlsx', index=False)\n",
    "\n",
    "print(\"Data saved to Excel files successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebecee8-7a3e-4293-8d75-d2df3aa4d3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
